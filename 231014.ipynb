{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1WV3G26pMkVJCxuADVc8EivhCgRoQ0hvn",
      "authorship_tag": "ABX9TyMRtprsK4YpUlDzEh5Z7McG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/SuperResolution/blob/main/231014.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em_0oI8lBPbm"
      },
      "outputs": [],
      "source": [
        "# Created By unknown-user(Hyundai CTO Dacon)\n",
        "# From 23.10.14"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Lambda, Input, Conv2D, Add\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import scipy.ndimage as ndimage\n",
        "from scipy.ndimage import median_filter, uniform_filter\n"
      ],
      "metadata": {
        "id": "wAVnWdx8Btz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salt and pepper Denoising\n",
        "\n",
        "def selective_median_filter(img, kernel_size=3, threshold1 = 0, threshold2 = 1):\n",
        "    # Masks where the image has values close to 0 or 1\n",
        "    mask_salt = img > (1.0 - threshold1) # white\n",
        "    mask_pepper = img < threshold2 # black\n",
        "    mask_combined = tf.math.logical_or(mask_salt, mask_pepper).numpy()\n",
        "\n",
        "    # Convert image to numpy for processing\n",
        "    img_numpy = img.numpy()\n",
        "\n",
        "    # Apply median filter only where the mask is true\n",
        "    for i in range(img_numpy.shape[2]):  # For each channel\n",
        "        channel = img_numpy[:,:,i]\n",
        "        channel_filtered = median_filter(channel, size=kernel_size)\n",
        "        #channel_filtered = uniform_filter(channel, size=kernel_size)\n",
        "        # Replace only the noisy pixels\n",
        "        channel[mask_combined[:,:,0]] = channel_filtered[mask_combined[:,:,0]]\n",
        "        img_numpy[:,:,i] = channel\n",
        "\n",
        "    return tf.convert_to_tensor(img_numpy, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "MyYelg6khuAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "directory_path_train_lr = \"/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/train_lr\"\n",
        "directory_path_train_hr = \"/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/train_hr\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "batch_size = 32\n",
        "image_slicing = 500\n",
        "\n",
        "lr_image_files = sorted([os.path.join(directory_path_train_lr, f) for f in os.listdir(directory_path_train_lr)])\n",
        "hr_image_files = sorted([os.path.join(directory_path_train_hr, f) for f in os.listdir(directory_path_train_hr)])\n",
        "\n",
        "lr_image_files_3000 = lr_image_files[:image_slicing]\n",
        "hr_image_files_3000 = hr_image_files[:image_slicing]\n",
        "\n",
        "# pre-processing\n",
        "def load_images(lr_path, hr_path):\n",
        "    lr = tf.io.read_file(lr_path)\n",
        "    lr = tf.image.decode_jpeg(lr, channels=3)\n",
        "    lr = tf.image.resize(lr, [256, 256])\n",
        "    lr = lr / 255.0\n",
        "    lr_filter = tf.py_function(func=selective_median_filter, inp=[lr], Tout=tf.float32)\n",
        "\n",
        "    hr = tf.io.read_file(hr_path)\n",
        "    hr = tf.image.decode_jpeg(hr, channels=3)\n",
        "    hr = tf.image.resize(hr, [1024, 1024])\n",
        "    hr = hr / 255.0\n",
        "\n",
        "    return lr, hr, lr_filter\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((lr_image_files_3000, hr_image_files_3000))\n",
        "train_dataset = train_dataset.map(load_images)\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "P6cbMpUNB70x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(dataset, num_samples=3):\n",
        "    for i, (lr_image, hr_image, lr_filter) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(lr_image.numpy())\n",
        "        plt.title(f\"Low Resolution Image {i+1}\")\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(lr_filter.numpy())\n",
        "        plt.title(f\"Filtering Image {i+1}\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(hr_image.numpy())\n",
        "        plt.title(f\"High Resolution Image {i+1}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "show_images(train_dataset)"
      ],
      "metadata": {
        "id": "7Yf2JVjqC2Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Super Resolution\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, scaling=0.1):\n",
        "    tmp = Conv2D(filters, kernel_size, padding='same', activation='relu')(x)\n",
        "    tmp = Conv2D(filters, kernel_size, padding='same')(tmp)\n",
        "    tmp = Add()([x, tmp])\n",
        "    return tmp\n",
        "\n",
        "def upsample(x, scale=4):\n",
        "    return Lambda(lambda x: tf.nn.depth_to_space(x, scale))(x)\n",
        "\n",
        "def EDSR(input_shape=(256,256,3), scale=4):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    x = Conv2D(64, 9, padding='same', activation='relu')(inputs)\n",
        "    for _ in range(5):  # Number of residual blocks\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    x = Conv2D(64, 3, padding='same')(x)\n",
        "    x = upsample(x, scale)\n",
        "    outputs = Conv2D(3, 9, padding='same')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = EDSR()\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "model.fit(train_dataset, epochs=20)"
      ],
      "metadata": {
        "id": "ojDrmHgRH7Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_lr_paths = lr_image_files_3000[:3]\n",
        "test_hr_paths = hr_image_files_3000[:3]\n",
        "\n",
        "\n",
        "for test_lr_path, test_hr_path in zip(test_lr_paths, test_hr_paths):\n",
        "\n",
        "    lr, hr = load_images(test_lr_path, test_hr_path)\n",
        "    lr_input = tf.expand_dims(lr, 0)\n",
        "\n",
        "    sr = model.predict(lr_input)\n",
        "    sr = np.clip(sr, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(tf.squeeze(lr))\n",
        "    plt.title(\"LR Image\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(tf.squeeze(sr))\n",
        "    plt.title(\"SR (Model Output) Image\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(tf.squeeze(hr))\n",
        "    plt.title(\"HR Image\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "40-BNiwgdVO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOHEQhtlgrrA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}