{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "gpuType": "T4",
      "mount_file_id": "1WV3G26pMkVJCxuADVc8EivhCgRoQ0hvn",
      "authorship_tag": "ABX9TyMniHzZff95XegRDxUxhV0P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/SuperResolution/blob/main/231025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em_0oI8lBPbm"
      },
      "outputs": [],
      "source": [
        "# Created By unknown-user(Hyundai CTO Dacon)\n",
        "# From 23.10.14"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip\n",
        "#%cd /content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/train_hr\n",
        "#!unzip -qq \"/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/train_hr/hr.zip\""
      ],
      "metadata": {
        "id": "7e9o8B1dlijR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n"
      ],
      "metadata": {
        "id": "bBMKJTCs_Odl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salt and pepper Denoising\n",
        "\n",
        "def selective_median_filter(img, kernel_size=3, threshold1 = 0, threshold2 = 1):\n",
        "    # Masks where the image has values close to 0 or 1\n",
        "    mask_salt = img > (1.0 - threshold1) # white\n",
        "    mask_pepper = img < threshold2 # black\n",
        "    mask_combined = tf.math.logical_or(mask_salt, mask_pepper).numpy()\n",
        "\n",
        "    # Convert image to numpy for processing\n",
        "    img_numpy = img.numpy()\n",
        "\n",
        "    # Apply median filter only where the mask is true\n",
        "    for i in range(img_numpy.shape[2]):  # For each channel\n",
        "        channel = img_numpy[:,:,i]\n",
        "        channel_filtered = median_filter(channel, size=kernel_size)\n",
        "        #channel_filtered = uniform_filter(channel, size=kernel_size)\n",
        "        # Replace only the noisy pixels\n",
        "        channel[mask_combined[:,:,0]] = channel_filtered[mask_combined[:,:,0]]\n",
        "        img_numpy[:,:,i] = channel\n",
        "\n",
        "    return tf.convert_to_tensor(img_numpy, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "MyYelg6khuAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Lambda, Input, Add, Dense, Reshape, Flatten, UpSampling2D, Conv2D, LeakyReLU, BatchNormalization, Activation,Conv2DTranspose\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
        "import numpy as np\n",
        "import scipy.ndimage as ndimage\n",
        "from scipy.ndimage import median_filter, uniform_filter\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import random\n",
        "import cv2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.callbacks import Callback\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import load_model\n"
      ],
      "metadata": {
        "id": "wAVnWdx8Btz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "directory_path_train_lr = \"/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/train_lr\"\n",
        "directory_path_train_hr = \"/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/train_hr\""
      ],
      "metadata": {
        "id": "P6cbMpUNB70x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "start_slicing = 0\n",
        "end_slicing = 10000\n",
        "image_slicing = end_slicing - start_slicing\n",
        "\n",
        "train_split = int(0.97 * image_slicing)\n",
        "val_split = image_slicing - train_split\n",
        "\n",
        "lr_image_files = sorted([os.path.join(directory_path_train_lr, f) for f in os.listdir(directory_path_train_lr)])\n",
        "hr_image_files = sorted([os.path.join(directory_path_train_hr, f) for f in os.listdir(directory_path_train_hr)])\n",
        "\n",
        "lr_image_files_3000 = lr_image_files[start_slicing:start_slicing + train_split]\n",
        "hr_image_files_3000 = hr_image_files[start_slicing:start_slicing + train_split]\n",
        "val_lr_files = lr_image_files[start_slicing + train_split:end_slicing]\n",
        "val_hr_files = hr_image_files[start_slicing + train_split:end_slicing]\n",
        "\n",
        "# pre-processing\n",
        "def load_images(lr_path, hr_path):\n",
        "    lr = tf.io.read_file(lr_path)\n",
        "    lr = tf.image.decode_jpeg(lr, channels=3)\n",
        "    lr = tf.image.resize(lr, [256, 256])\n",
        "    lr = lr / 255.0\n",
        "    lr_filter = tf.py_function(func=selective_median_filter, inp=[lr], Tout=tf.float32)\n",
        "\n",
        "    hr = tf.io.read_file(hr_path)\n",
        "    hr = tf.image.decode_jpeg(hr, channels=3)\n",
        "    hr = tf.image.resize(hr, [1024, 1024])\n",
        "    hr = hr / 255.0\n",
        "\n",
        "    return lr_filter, hr\n",
        "    #return lr, hr, lr_filter\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((lr_image_files_3000, hr_image_files_3000))\n",
        "train_dataset = train_dataset.map(load_images)\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_lr_files, val_hr_files))\n",
        "val_dataset = val_dataset.map(load_images)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "ZcjIcI1O6nmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files_in_directory(directory_path):\n",
        "    try:\n",
        "        # 디렉토리에 있는 파일 리스트 가져오기\n",
        "        files = os.listdir(directory_path)\n",
        "\n",
        "        # 이미지 파일만 골라내기 (예: jpg, png 파일)\n",
        "        image_files = [file for file in files if file.endswith(('.jpg', '.png'))]\n",
        "\n",
        "        # 이미지 파일의 수 반환\n",
        "        return len(image_files)\n",
        "\n",
        "    except Exception as e:\n",
        "        # 오류 발생 시 메시지 출력\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "print(f\"Number of images in {directory_path_train_lr}: {count_files_in_directory(directory_path_train_lr)}\")\n",
        "print(f\"Number of images in {directory_path_train_hr}: {count_files_in_directory(directory_path_train_hr)}\")"
      ],
      "metadata": {
        "id": "9Ss1FnhEhbgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(dataset, num_samples=3):\n",
        "    #for i, (lr_image, hr_image, lr_filter) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "    for i, (lr_image, hr_image) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(lr_image.numpy())\n",
        "        plt.title(f\"Low Resolution Image {i+1}\")\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        #plt.imshow(lr_filter.numpy())\n",
        "        plt.title(f\"Filtering Image {i+1}\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(hr_image.numpy())\n",
        "        plt.title(f\"High Resolution Image {i+1}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "show_images(val_dataset)"
      ],
      "metadata": {
        "id": "ynQMfj2_CKGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(dataset, num_samples=3):\n",
        "    #for i, (lr_image, hr_image, lr_filter) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "    for i, (lr_image, hr_image) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(lr_image.numpy())\n",
        "        plt.title(f\"Low Resolution Image {i+1}\")\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        #plt.imshow(lr_filter.numpy())\n",
        "        plt.title(f\"Filtering Image {i+1}\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(hr_image.numpy())\n",
        "        plt.title(f\"High Resolution Image {i+1}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "show_images(train_dataset)"
      ],
      "metadata": {
        "id": "7Yf2JVjqC2Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Super Resolution\n",
        "\n",
        "def combined_loss(alpha):\n",
        "    mse_loss = MeanSquaredError()\n",
        "    mae_loss = MeanAbsoluteError()\n",
        "\n",
        "    def loss_function(y_true, y_pred):\n",
        "        # Calculate MSE\n",
        "        mse = mse_loss(y_true, y_pred)\n",
        "        mae = mae_loss(y_true, y_pred)\n",
        "\n",
        "        # Calculate PSNR\n",
        "        max_pixel = 1.0\n",
        "        psnr = 1.0 * (-10.0 * tf.math.log(max_pixel**2 / (mse + 1e-10)) / tf.math.log(10.0))\n",
        "\n",
        "        # Combine the MSE and PSNR with a weight\n",
        "        # combined_loss = alpha * mse + (1 - alpha) * psnr\n",
        "        # combined_loss = alpha * mae + (1 - alpha) * psnr\n",
        "        combined_loss = mae + mse\n",
        "\n",
        "        return combined_loss\n",
        "\n",
        "    return loss_function\n",
        "\n",
        "def psnr_loss(y_true, y_pred):\n",
        "    # Assuming the images are scaled between 0 and 1\n",
        "    max_pixel = 1.0\n",
        "    # Compute MSE\n",
        "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    # Compute PSNR loss\n",
        "    return -10 * tf.math.log(max_pixel**2 / (mse + 1e-10)) / tf.math.log(10.0)\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, scaling=0.1):\n",
        "    tmp = Conv2D(filters, kernel_size, padding='same', activation='relu')(x)\n",
        "    tmp = Conv2D(filters, kernel_size, padding='same')(tmp)\n",
        "    tmp = Add()([x, tmp])\n",
        "    return tmp\n",
        "\n",
        "def upsample(x, scale=4):\n",
        "    return Lambda(lambda x: tf.nn.depth_to_space(x, scale))(x)\n",
        "\n",
        "def EDSR(input_shape=(256,256,3), scale=4):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    x = Conv2D(64, 3, padding='same', activation='relu')(inputs)\n",
        "    for _ in range(9):  # Number of residual blocks\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    x = Conv2D(64, 3, padding='same')(x)\n",
        "    x = upsample(x, scale)\n",
        "    outputs = Conv2D(3, 3, padding='same')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = EDSR()\n",
        "optimizer = Adam(learning_rate = 1e-3)\n",
        "#model.compile(optimizer=optimizer, loss = 'mean_absolute_error')\n",
        "model.compile(optimizer=optimizer, loss=combined_loss(alpha=1))\n",
        "#model.compile(optimizer=optimizer, loss = 'mse')\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ojDrmHgRH7Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PSNRCallback(Callback):\n",
        "    def __init__(self, val_dataset):\n",
        "        super().__init__()\n",
        "        self.val_dataset = val_dataset\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        total_psnr = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for x_val, y_val in self.val_dataset:\n",
        "            y_pred = self.model.predict(x_val)\n",
        "\n",
        "            # Assuming the images are scaled between 0 and 1\n",
        "            max_pixel = 1.0\n",
        "            mse = tf.reduce_mean(tf.square(y_val - y_pred))\n",
        "            psnr = -10.0 * tf.math.log(mse + 1e-10) / tf.math.log(10.0)\n",
        "\n",
        "            total_psnr += psnr\n",
        "            num_batches += 1\n",
        "\n",
        "        average_psnr = total_psnr / num_batches\n",
        "        logs[\"val_psnr\"] = average_psnr\n",
        "        print(f\"\\nValidation PSNR after epoch {epoch+1}: {average_psnr:.4f} dB\")\n",
        "\n",
        "class CustomLRScheduler(Callback):\n",
        "    def __init__(self, lr_decay_factor, decay_interval=10):\n",
        "        super().__init__()\n",
        "        self.lr_decay_factor = lr_decay_factor\n",
        "        self.decay_interval = decay_interval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.decay_interval == 0:\n",
        "            current_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "            new_lr = current_lr * self.lr_decay_factor\n",
        "            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
        "            print(f\"\\nSetting learning rate to {new_lr}\")\n",
        "\n",
        "lr_decay_factor = 0.5\n",
        "custom_lr_scheduler = CustomLRScheduler(lr_decay_factor=lr_decay_factor)\n",
        "\n",
        "# Usage in model.fit()\n",
        "psnr_callback = PSNRCallback(val_dataset=val_dataset)"
      ],
      "metadata": {
        "id": "GtVDb8h-hyt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "\n",
        "#early_stopping = EarlyStopping(monitor='val_psnr', patience=5, verbose=1, restore_best_weights=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
        "history = model.fit(train_dataset, epochs=5, validation_data=val_dataset, callbacks=[psnr_callback, early_stopping, reduce_lr])"
      ],
      "metadata": {
        "id": "EpALNh-3BOEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s = load_model('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231024/code/4.h5', custom_objects={'loss_function': combined_loss(alpha=1)})\n",
        "model_s.summary()"
      ],
      "metadata": {
        "id": "s7VRrIRbQVjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Training\n",
        "new_learning_rate = 1e-5\n",
        "optimizer = Adam(learning_rate=new_learning_rate)\n",
        "model_s.compile(optimizer=optimizer, loss=combined_loss(alpha=1))\n",
        "reduce_lr2 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=1e-6)\n",
        "history = model_s.fit(train_dataset, epochs=3, validation_data=val_dataset, callbacks=[psnr_callback, early_stopping, reduce_lr2])"
      ],
      "metadata": {
        "id": "vO-gYNy-jEkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s.save('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231024/code/1.h5')"
      ],
      "metadata": {
        "id": "k4kb616nqsea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s2 = load_model('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231024/code/1.h5', custom_objects={'loss_function': combined_loss(alpha=1)})"
      ],
      "metadata": {
        "id": "jA7gVpfyqutx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Training\n",
        "new_learning_rate = 1e-4\n",
        "optimizer = Adam(learning_rate=new_learning_rate)\n",
        "model_s2.compile(optimizer=optimizer, loss=combined_loss(alpha=1))\n",
        "reduce_lr2 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
        "history = model_s2.fit(train_dataset, epochs=5, validation_data=val_dataset, callbacks=[psnr_callback, early_stopping, reduce_lr2])"
      ],
      "metadata": {
        "id": "Qsyb7o1prFTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(dataset, num_samples=3):\n",
        "    #for i, (lr_image, hr_image, lr_filter) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "    for i, (lr_image, hr_image) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(lr_image.numpy())\n",
        "        plt.title(f\"Low Resolution Image {i+1}\")\n",
        "\n",
        "        lr_image = tf.expand_dims(lr_image, 0)\n",
        "        sr = model_s2.predict(lr_image)\n",
        "        sr = np.clip(sr, 0, 1)\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(tf.squeeze(sr))\n",
        "        plt.title(f\"Super Resolution Image {i+1}\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(hr_image.numpy())\n",
        "        plt.title(f\"High Resolution Image {i+1}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "show_images(train_dataset)"
      ],
      "metadata": {
        "id": "40-BNiwgdVO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s2.save('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231024/code/2.h5')\n",
        "model_s3 = load_model('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231024/code/2.h5', custom_objects={'loss_function': combined_loss(alpha=1)})"
      ],
      "metadata": {
        "id": "SAE9NACeTAjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Training\n",
        "new_learning_rate = 1e-3\n",
        "optimizer = Adam(learning_rate=new_learning_rate)\n",
        "model_s3.compile(optimizer=optimizer, loss=combined_loss(alpha=1))\n",
        "reduce_lr2 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=1e-6)\n",
        "history = model_s3.fit(train_dataset, epochs=3, validation_data=val_dataset, callbacks=[psnr_callback, early_stopping, reduce_lr2])"
      ],
      "metadata": {
        "id": "-ixkqwCqy2AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s3.save('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231023/code/3.h5')\n",
        "model_s4 = load_model('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231023/code/3.h5', custom_objects={'loss_function': combined_loss(alpha=1)})"
      ],
      "metadata": {
        "id": "SroD-LT2jhFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Training\n",
        "new_learning_rate = 1e-5\n",
        "optimizer = Adam(learning_rate=new_learning_rate)\n",
        "model_s4.compile(optimizer=optimizer, loss=combined_loss(alpha=1))\n",
        "reduce_lr2 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
        "history = model_s4.fit(train_dataset, epochs=2, validation_data=val_dataset, callbacks=[psnr_callback, early_stopping, reduce_lr2])"
      ],
      "metadata": {
        "id": "8ih8j4SE73SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s4.save('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231024/code/4.h5')\n",
        "model_s5 = load_model('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231024/code/4.h5', custom_objects={'loss_function': combined_loss(alpha=1)})"
      ],
      "metadata": {
        "id": "qgriioLltNe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Training\n",
        "new_learning_rate = 5e-4\n",
        "optimizer = Adam(learning_rate=new_learning_rate)\n",
        "model_s5.compile(optimizer=optimizer, loss=combined_loss(alpha=1))\n",
        "reduce_lr2 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, min_lr=1e-6)\n",
        "history = model_s5.fit(train_dataset, epochs=30, validation_data=val_dataset, callbacks=[psnr_callback, early_stopping, reduce_lr2])"
      ],
      "metadata": {
        "id": "K037O3KxDirr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s5.save('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231023/code/5.h5')\n",
        "model_s6 = load_model('/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231023/code/5.h5', custom_objects={'loss_function': combined_loss(alpha=1)})"
      ],
      "metadata": {
        "id": "VCsVWiX-2rtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Training\n",
        "new_learning_rate = 5e-4\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
        "optimizer = Adam(learning_rate=new_learning_rate)\n",
        "model_s6.compile(optimizer=optimizer, loss=combined_loss(alpha=1))\n",
        "reduce_lr2 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, min_lr=1e-6)\n",
        "history = model_s6.fit(train_dataset, epochs=5, validation_data=val_dataset, callbacks=[psnr_callback, early_stopping, reduce_lr2])"
      ],
      "metadata": {
        "id": "mbyy4OrRci0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(dataset, num_samples=3):\n",
        "    #for i, (lr_image, hr_image, lr_filter) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "    for i, (lr_image, hr_image) in enumerate(dataset.unbatch().take(num_samples)):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(lr_image.numpy())\n",
        "        plt.title(f\"Low Resolution Image {i+1}\")\n",
        "\n",
        "        lr_image = tf.expand_dims(lr_image, 0)\n",
        "        sr = model_s6.predict(lr_image)\n",
        "        sr = np.clip(sr, 0, 1)\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(tf.squeeze(sr))\n",
        "        plt.title(f\"Super Resolution Image {i+1}\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(hr_image.numpy())\n",
        "        plt.title(f\"High Resolution Image {i+1}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "show_images(train_dataset)"
      ],
      "metadata": {
        "id": "SPDJ5wEJddfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testifying\n",
        "\n",
        "directory_path_test_lr = \"/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test/lr\"\n",
        "test_image_files = sorted([os.path.join(directory_path_test_lr, fname) for fname in os.listdir(directory_path_test_lr) if fname.endswith('.png') or fname.endswith('.jpg')])\n",
        "\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = load_img(img_path, target_size=(256, 256))\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0\n",
        "    img_filter = tf.py_function(func=selective_median_filter, inp=[img], Tout=tf.float32)\n",
        "    return img_filter\n",
        "\n",
        "selected_test_image_files = random.sample(test_image_files, 10)\n",
        "\n",
        "for test_img_path in selected_test_image_files:\n",
        "    test_img = load_and_preprocess_image(test_img_path)\n",
        "    test_img_input = tf.expand_dims(test_img, 0)\n",
        "\n",
        "    sr_img = model_s3.predict(test_img_input)\n",
        "    sr_img = tf.squeeze(sr_img)\n",
        "    sr_img = np.clip(sr_img, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(test_img)\n",
        "    plt.title(\"LR Image\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(sr_img)\n",
        "    plt.title(\"SR Image\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uOHEQhtlgrrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data saving for submission-1\n",
        "\n",
        "directory_path_test_lr = \"/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test/lr\"\n",
        "test_image_files = [os.path.join(directory_path_test_lr, fname) for fname in os.listdir(directory_path_test_lr) if fname.endswith('.png') or fname.endswith('.jpg')]\n",
        "\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = load_img(img_path, target_size=(256, 256))\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0\n",
        "    img_filter = tf.py_function(func=selective_median_filter, inp=[img], Tout=tf.float32)\n",
        "    return img_filter\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab_Notebooks/Hyundai_Daycon/test_hr/231024/2\"\n",
        "\n",
        "for test_img_path in test_image_files:\n",
        "    test_img = load_and_preprocess_image(test_img_path)\n",
        "    test_img_input = tf.expand_dims(test_img, 0)\n",
        "\n",
        "    sr_img = model_s5.predict(test_img_input)\n",
        "    sr_img = tf.squeeze(sr_img).numpy()\n",
        "    sr_img = np.clip(sr_img * 255, 0, 255).astype(np.uint8)  #De-normalizing\n",
        "    # RGB to BGR\n",
        "    sr_img_bgr = cv2.cvtColor(sr_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Use the same filename from input\n",
        "    filename = os.path.join(save_directory, os.path.basename(test_img_path))\n",
        "\n",
        "    cv2.imwrite(filename, sr_img_bgr)\n"
      ],
      "metadata": {
        "id": "aC9dSvM9sszz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model save\n",
        "\n",
        "model_path = os.path.join(save_directory, '231017_model_117.h5')\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "9rcbLc1Vhs5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional Super Resolution Algorithm\n",
        "\n",
        "def generate_sr_images(lr_images, hr_images):\n",
        "    sr_images = model(lr_images)\n",
        "    return sr_images, hr_images\n",
        "\n",
        "train_dataset_sr = train_dataset.map(generate_sr_images)\n",
        "val_dataset_sr = val_dataset.map(generate_sr_images)\n",
        "\n",
        "second_model = Sequential([\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(1024, 1024, 3)),\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    Conv2D(3,(3, 3), padding='same', activation='relu')\n",
        "])\n",
        "second_model.compile(optimizer='adam', loss='mse')\n",
        "second_model.summary()"
      ],
      "metadata": {
        "id": "9MMlLD_v5FFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Second training\n",
        "second_model.fit(train_dataset_sr, epochs=3, validation_data=val_dataset_sr)"
      ],
      "metadata": {
        "id": "9u8a03PM8ytg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "\n",
        "sample_lr_images, sample_hr_images = next(iter(train_dataset.take(3)))\n",
        "\n",
        "first_model_outputs = model.predict(sample_lr_images)\n",
        "second_model_outputs = second_model.predict(first_model_outputs)\n",
        "\n",
        "sr_img = tf.squeeze(sr_img)\n",
        "sr_img = np.clip(sr_img, 0, 1)\n",
        "\n",
        "fig, axs = plt.subplots(10, 4, figsize=(15, 30))\n",
        "\n",
        "for i in range(10):\n",
        "    axs[i, 0].imshow(sample_lr_images[i].numpy())\n",
        "    axs[i, 0].set_title('LR Image')\n",
        "    axs[i, 0].axis('off')\n",
        "\n",
        "    axs[i, 1].imshow(first_model_outputs[i])\n",
        "    axs[i, 1].set_title('First Model Output')\n",
        "    axs[i, 1].axis('off')\n",
        "\n",
        "    axs[i, 2].imshow(second_model_outputs[i])\n",
        "    axs[i, 2].set_title('Second Model Output')\n",
        "    axs[i, 2].axis('off')\n",
        "\n",
        "    axs[i, 3].imshow(sample_hr_images[i].numpy())\n",
        "    axs[i, 3].set_title('HR Image')\n",
        "    axs[i, 3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iu0wPvsKCstx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}